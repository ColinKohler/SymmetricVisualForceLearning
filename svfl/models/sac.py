import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal

from escnn import group
from escnn import gspaces
from escnn import nn as enn

from svfl import torch_utils
from svfl.models.latent import Latent
from svfl.models.layers import EquivariantBlock, ConvBlock

class Critic(nn.Module):
  '''
  Twin-head Critic model.
  '''
  def __init__(self, vision_size, action_dim, equivariant=True, z_dim=8, encoder='fusion', initialize=True, N=8):
    super().__init__()

    self.equivariant = equivariant
    self.z_dim = z_dim
    self.action_dim = action_dim
    self.N = N

    self.G = group.so2_group()
    self.gspace = gspaces.no_base_space(self.G)

    self.encoder = Latent(equivariant=equivariant, vision_size=vision_size, z_dim=z_dim, encoder=encoder, initialize=initialize)

    self.action_type = self.gspace.type(self.G.irrep(0) + self.G.irrep(0) + self.G.irrep(0) + self.G.standard_representation())
    self.in_type = self.encoder.out_type + self.action_type
    self.out_type = self.gspace.type(self.G.irrep(0))

    self.critic_1 = enn.Linear(self.in_type, self.out_type)
    self.critic_2 = enn.Linear(self.in_type, self.out_type)

  def forward(self, obs, act):
    batch_size = obs[0].size(0)
    z = self.encoder(obs)

    dxy = act[:, 1:3]
    inv_act = torch.cat((act[:,0:1], act[:,3:]), dim=1)

    cat = torch.cat((z.tensor, inv_act, dxy), dim=1)
    cat_geo = enn.GeometricTensor(cat, self.in_type)

    out_1 = self.critic_1(cat_geo).tensor
    out_2 = self.critic_2(cat_geo).tensor

    return out_1, out_2

class GaussianPolicy(nn.Module):
  '''
  Policy model that uses a Normal distribution to sample actions.
  '''
  def __init__(self, vision_size, action_dim, equivariant=True, z_dim=8, encoder='fusion', initialize=True, N=8):
    super().__init__()
    self.log_sig_min = -20
    self.log_sig_max = 2
    self.eps = 1e-6

    self.equivariant = equivariant
    self.action_dim = action_dim
    self.z_dim = z_dim
    self.initialize = initialize
    self.N = N

    self.G = group.so2_group()
    self.gspace = gspaces.no_base_space(self.G)

    self.encoder = Latent(equivariant=equivariant, vision_size=vision_size, z_dim=z_dim, encoder=encoder, initialize=initialize)
    self.in_type = self.encoder.out_type
    self.out_type = self.gspace.type(
      self.G.standard_representation() + self.G.irrep(0) + self.G.irrep(0) + self.G.irrep(0) + \
      self.G.irrep(0) + self.G.irrep(0) + self.G.irrep(0) + self.G.irrep(0) + self.G.irrep(0)
    )

    self.policy = enn.Linear(self.in_type, self.out_type)

  def forward(self, obs):
    z  = self.encoder(obs)

    out = self.policy(z).tensor

    dxy = out[:, 0:2]
    inv_act = out[:, 2:self.action_dim]

    mean = torch.cat((inv_act[:, 0:1], dxy, inv_act[:, 1:]), dim=1)
    log_std = out[:, self.action_dim:]
    log_std = torch.clamp(log_std, min=self.log_sig_min, max=self.log_sig_max)

    return mean, log_std

  def sample(self, obs):
    '''
    Sample an action from a Normal distribution generated by the model.
    '''
    mean, log_std = self.forward(obs)
    std = log_std.exp()

    normal = Normal(mean, std)
    x_t = normal.rsample()
    y_t = torch.tanh(x_t)
    action = y_t

    log_prob = normal.log_prob(x_t)
    log_prob -= torch.log((1 - y_t.pow(2)) + self.eps)
    log_prob = log_prob.sum(1, keepdim=True)
    mean = torch.tanh(mean)

    return action, log_prob, mean
