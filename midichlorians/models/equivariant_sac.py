import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.distributions import Normal

from escnn import gspaces
from escnn import nn as enn

from midichlorians.models.encoders.equiv_depth_encoder import EquivariantDepthEncoder
from midichlorians.models.layers import EquivariantBlock

class EquivariantCritic(nn.Module):
  '''
  Equivariant critic model.
  '''
  def __init__(self, action_dim, z_dim=64, deterministic=True, initialize=True, N=8):
    super().__init__()
    self.z_dim = z_dim
    self.action_dim = action_dim
    self.N = N
    self.deterministic = deterministic

    self.c4_act = gspaces.rot2dOnR2(self.N)
    self.n_rho1 = 1
    self.z_repr = self.z_dim * [self.c4_act.trivial_repr]
    self.invariant_action_repr = (self.action_dim - 2) * [self.c4_act.trivial_repr]
    self.equivariant_action_repr = self.n_rho1 * [self.c4_act.irrep(1)]

    self.in_type = enn.FieldType(self.c4_act, self.z_repr + self.invariant_action_repr + self.equivariant_action_repr)
    self.inner_type = enn.FieldType(self.c4_act, self.z_dim * [self.c4_act.regular_repr])
    self.inner_type_2 = enn.FieldType(self.c4_act, self.z_dim * [self.c4_act.trivial_repr])
    self.out_type = enn.FieldType(self.c4_act, 1 * [self.c4_act.trivial_repr])

    self.depth_enc = EquivariantDepthEncoder(z_dim=z_dim, initialize=initialize, N=N)

    self.critic_1 = nn.Sequential(
      EquivariantBlock(self.in_type, self.inner_type, kernel_size=1, stride=1, padding=0, initialize=initialize),
      enn.GroupPooling(self.inner_type),
      EquivariantBlock(self.inner_type_2, self.out_type, kernel_size=1, stride=1, padding=0, initialize=initialize, act=False)
    )

    self.critic_2 = nn.Sequential(
      EquivariantBlock(self.in_type, self.inner_type, kernel_size=1, stride=1, padding=0, initialize=initialize),
      enn.GroupPooling(self.inner_type),
      EquivariantBlock(self.inner_type_2, self.out_type, kernel_size=1, stride=1, padding=0, initialize=initialize, act=False)
    )

  def forward(self, obs, act):
    batch_size = obs.size(0)

    z = self.depth_enc(obs)

    dxy = act[:, 1:3].reshape(batch_size,  2, 1, 1)

    inv_act = torch.cat((act[:,0:1], act[:,3:]), dim=1)
    n_inv = inv_act.shape[1]
    inv_act = inv_act.reshape(batch_size, n_inv, 1, 1)

    cat = torch.cat((z.tensor, inv_act, dxy), dim=1)
    cat_geo = enn.GeometricTensor(cat, self.in_type)

    out_1 = self.critic_1(cat_geo).tensor.reshape(batch_size, 1)
    out_2 = self.critic_2(cat_geo).tensor.reshape(batch_size, 1)

    return out_1, out_2

class EquivariantGaussianPolicy(nn.Module):
  '''
  Equivariant actor model that uses a Normal distribution to sample actions.
  '''
  def __init__(self, action_dim, z_dim=64, deterministic=True, initialize=True, N=8):
    super().__init__()
    self.log_sig_min = -20
    self.log_sig_max = 2
    self.eps = 1e-6

    self.action_dim = action_dim
    self.z_dim = z_dim
    self.initialize = initialize
    self.deterministic = deterministic

    self.c4_act = gspaces.rot2dOnR2(N)
    self.n_rho1 = 1
    self.z_repr = self.z_dim * [self.c4_act.trivial_repr]
    self.invariant_action_repr = (self.action_dim * 2 - 2) * [self.c4_act.trivial_repr]
    self.equivariant_action_repr = self.n_rho1 * [self.c4_act.irrep(1)]

    self.in_type = enn.FieldType(self.c4_act, self.z_repr)
    self.out_type = enn.FieldType(self.c4_act, self.equivariant_action_repr + self.invariant_action_repr)

    self.enc = EquivariantDepthEncoder(z_dim=z_dim, initialize=initialize, N=N)

    out_type = enn.FieldType(self.c4_act, self.z_dim * [self.c4_act.regular_repr])
    self.conv_1 = EquivariantBlock(self.in_type, out_type, kernel_size=1, stride=1, padding=0, initialize=initialize, act=False)
    in_type = out_type
    self.conv_2 = EquivariantBlock(in_type, self.out_type, kernel_size=1, stride=1, padding=0, initialize=initialize, act=False)

  def forward(self, obs):
    batch_size = obs.size(0)

    z = self.enc(obs)
    out = self.conv(z).tensor.reshape(batch_size, -1)

    dxy = out[:, 0:2]
    inv_act = out[:, 2:self.action_dim]

    mean = torch.cat((inv_act[:, 0:1], dxy, inv_act[:, 1:]), dim=1)
    log_std = out[:, self.action_dim:]
    log_std = torch.clamp(log_std, min=self.log_sig_min, max=self.log_sig_max)

    if self.deterministic:
      return mean, log_std, z
    else:
      return mean, log_std, z, mu_z, var_z, mu_prior, z_prior

  def sample(self, x):
    '''
    Sample an action from a Normal distribution generated by the model.
    '''
    if self.deterministic:
      mean, log_std, z = self.forward(x)
    else:
      mean, log_std, z, mu_z, var_z, mu_prior, z_prior = self.forward(x)
    std = log_std.exp()

    normal = Normal(mean, std)
    x_t = normal.rsample()
    y_t = torch.tanh(x_t)
    action = y_t

    log_prob = normal.log_prob(x_t)
    log_prob -= torch.log((1 - y_t.pow(2)) + self.eps)
    log_prob = log_prob.sum(1, keepdim=True)
    mean = torch.tanh(mean)

    if self.deterministic:
      return action, log_prob, mean, z
    else:
      return action, log_prob, mean, z, muz_z, var_z, mu_prior, z_prior
